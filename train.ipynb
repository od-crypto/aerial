{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lib.train import trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106820 2435\n"
     ]
    }
   ],
   "source": [
    "def root(name):\n",
    "    return \"-\".join(name.split(\"/\")[-1].split(\".\")[-2].split(\"-\")[:-2 or None])\n",
    "\n",
    "root_path_landcover = 'datasets/landcover_processed/rotated_crops/'\n",
    "list_dataset_landcover = list(filter(lambda x: x.endswith('.png'), os.listdir(root_path_landcover)))\n",
    "list_dataset_landcover = list(map(lambda x: root_path_landcover + x, list_dataset_landcover))\n",
    "# list_dataset_landcover = list_dataset_landcover[7000:10000]\n",
    "list_dataset_landcover = list_dataset_landcover\n",
    "\n",
    "root_path_sentinel = 'datasets/sentinel_processed/rotated_crops/'\n",
    "list_dataset_sentinel = list(filter(lambda x: x.endswith('.png'), os.listdir(root_path_sentinel)))\n",
    "list_dataset_sentinel = list(map(lambda x: root_path_sentinel + x, list_dataset_sentinel))\n",
    "# list_dataset_sentinel = list_dataset_sentinel[7000:10000]\n",
    "list_dataset_sentinel = list_dataset_sentinel\n",
    "\n",
    "list_dataset = list_dataset_landcover + list_dataset_sentinel\n",
    "#list_dataset = list_dataset[7000:7500]\n",
    "list_dataset = list_dataset\n",
    "\n",
    "list_root = [root(name) for name in list_dataset]\n",
    "list_root = list(set(list_root))\n",
    "\n",
    "train_root_list, test_root_list = train_test_split(list_root, test_size=0.15)\n",
    "\n",
    "train_img_list = []\n",
    "test_img_list = []\n",
    "for name in list_dataset:\n",
    "    rname = root(name)\n",
    "    if rname in test_root_list and name.endswith('-0.png'):\n",
    "        test_img_list.append(name)\n",
    "    elif rname in train_root_list:\n",
    "        train_img_list.append(name)\n",
    "        \n",
    "print(len(train_img_list), len(test_img_list))\n",
    "# with open('train_img_list_landcover.json', 'w') as f:\n",
    "with open('train_img_list_total.json', 'w') as f:\n",
    "    json.dump(train_img_list, f)\n",
    "    \n",
    "# with open('test_img_list_landcover.json', 'w') as f:\n",
    "with open('test_img_list_total.json', 'w') as f:\n",
    "    json.dump(test_img_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03465839884841103"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa = 1/(95898/3443)\n",
    "kappa / (1 + kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"from_scratch_landcover\": {\n",
    "        \"use_pretrained_vgg\": False,\n",
    "        \"pretrained_model\": None,\n",
    "        \"train_img_list\": \"train_img_list_landcover.json\",\n",
    "        \"test_img_list\": \"test_img_list_landcover.json\",\n",
    "        \"batch_size\": 40,\n",
    "        \"num_epochs\": 9,\n",
    "        \"lr\": 0.0001\n",
    "    },\n",
    "    \"from_scratch_sentinel\": {\n",
    "        \"use_pretrained_vgg\": False,\n",
    "        \"pretrained_model\": None,\n",
    "        \"train_img_list\": \"train_img_list_sentinel.json\",\n",
    "        \"test_img_list\": \"test_img_list_sentinel.json\",\n",
    "        \"batch_size\": 40,\n",
    "        \"num_epochs\": 20,\n",
    "        \"lr\": 0.0001\n",
    "},\n",
    "    \"from_scratch_total\": {\n",
    "        \"use_pretrained_vgg\": False,\n",
    "        \"pretrained_model\": None,\n",
    "        \"train_img_list\": \"train_img_list_total.json\",\n",
    "        \"test_img_list\": \"test_img_list_total.json\",\n",
    "        \"batch_size\": 80,\n",
    "        \"num_epochs\": 20,\n",
    "        \"lr\": 0.0001\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "train step\n"
     ]
    }
   ],
   "source": [
    "bs = cfg['from_scratch_total']['batch_size']\n",
    "ne = cfg['from_scratch_total']['num_epochs']\n",
    "lr = cfg['from_scratch_total']['lr']\n",
    "bs, ne, lr\n",
    "\n",
    "trainer(cfg['from_scratch_total'], train_id=f'from_scratch_total_nofreeze_bs{bs}_ne{ne}_lr{lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pylab as plt\n",
    "\n",
    "#with open('history-from_scratch_landcover_bs30_ne3_lr0.0001.json', 'r') as f:\n",
    "#    history_dict = json.load(f)\n",
    "\n",
    "#plt.plot(history_dict['val_loss'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
