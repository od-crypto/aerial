{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "import ternausnet.models\n",
    "# model = ternausnet.models.UNet11(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'datasets/landcover_processed/rotated_crops/'\n",
    "list_dataset = list(filter(lambda x: x.endswith('.png'), os.listdir(root_path)))\n",
    "list_dataset = list(map(lambda x: root_path + x, list_dataset))\n",
    "list_dataset = list_dataset[:1000]\n",
    "#train_img_list, test_img_list = train_test_split(list_dataset, test_size=0.15)\n",
    "#test_img_list = list(filter(lambda x: x.endswith('-0.png'), test_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root(name):\n",
    "    return \"-\".join(name.split(\"/\")[-1].split(\".\")[-2].split(\"-\")[:-2 or None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_root = [root(name) for name in list_dataset]\n",
    "list_root = list(set(list_root))\n",
    "len(list_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_list, test_root_list = train_test_split(list_root, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_root_list), len(test_root_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_list = []\n",
    "test_img_list = []\n",
    "for name in list_dataset:\n",
    "    if root(name) in test_root_list and name.endswith('-0.png'):\n",
    "        test_img_list.append(name)\n",
    "    else:\n",
    "        train_img_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_img_list), len(test_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_img_list), len(test_img_list))\n",
    "with open('train_img_list.json', 'w') as f:\n",
    "    json.dump(train_img_list, f)\n",
    "    \n",
    "with open('test_img_list.json', 'w') as f:\n",
    "    json.dump(test_img_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.train import WaterDataset, viz, train_transform, test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = WaterDataset('train_img_list.json', train_transform)\n",
    "d_val = WaterDataset('test_img_list.json', test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz2(s):\n",
    "    img = (s * torch.tensor([0.229, 0.224, 0.225])[:, None, None] + torch.tensor([0.485, 0.456, 0.406])[:, None,None])\n",
    "    print(img.min(), img.max(), img.shape)\n",
    "    img = (255 * (img.transpose(0,1).transpose(1,2).numpy())).astype(np.uint8)\n",
    "    print(img.shape)\n",
    "    plt.imshow(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_val[10][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "II = viz2(d_val[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "II.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('test_img_list.json', 'r') as f:\n",
    "    path = json.load(f)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "I = cv2.imread('datasets/landcover_processed/rotated_crops/N-34-66-C-c-4-3-773-60.png', cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "I = Image.open('datasets/landcover_processed/rotated_crops/N-34-66-C-c-4-3-773-60.png',).resize((224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist((II.astype(np.int32)-I[:,:,[2,1,0]].astype(np.int32)).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(II-I[:,:,[2,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I = cv2.resize(I, (224,224), interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I[:,:,[-1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(I[:, :, [2,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_val[3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Most interesting experiment is, to train the model from scratch... \n",
    "\n",
    "use_pretrained_vgg True/False  # False is pure UNET11, i.e. initialized with white noise\n",
    "pretrained model None/имя модели\n",
    "# (first one teches on landcover, then one loads a model, \n",
    "# trained on landcover and fine-tune it on sentinel dataset)\n",
    "train_img_list (create different train an dtest lists, whereas datasets are untouched)\n",
    "test_img_list\n",
    "num_epochs\n",
    "batch_size   ## should be the same for different models \n",
    "learning_rate  ## can be different for different models\n",
    "\n",
    "?? scheduler - what should it be? \n",
    "\n",
    "- unet + pretrained vgg11 [toloka]  // pretrained=False\n",
    "- unet + pretrained vgg11 [landcover] + [toloka] // pretrained=True (pretrained vgg)\n",
    "- unet + pretrained vgg11 [landcover, toloka] + [toloka]  (first train on landcover)\n",
    "- unet + pretrained vgg11 [landcover] + [toloka / 10]  # experiment on using only a small part of toloka, to train it additionally\n",
    "- unet + pretrained vgg11 [landcover, toloka / 10] + [toloka / 10]\n",
    "\n",
    "if use_pretrained_model is not None:\n",
    "    \n",
    "\n",
    "# Save maximum score somehow \n",
    "\n",
    "# the script uses the config (batch_size, learning rate, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = AccuracyMetric(0.5)\n",
    "\n",
    "pred = torch.tensor([0.6,0.4,0.1])\n",
    "gt = torch.tensor([1,0,1])\n",
    "\n",
    "acc.append(pred, gt)\n",
    "\n",
    "pred = torch.tensor([0.6,0.4,0.1])\n",
    "gt = torch.tensor([1,0,0])\n",
    "\n",
    "\n",
    "acc.append(pred, gt)\n",
    "\n",
    "acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_config.json', 'r') as f:\n",
    "    cfg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups = {'acccuracy': ['acc', 'val_acc'], 'bce-loss': ['loss', 'val_loss'], 'lake-acc': ['lakeacc', 'val_lakeacc']}\n",
    "# plotlosses = PlotLosses(groups=groups)\n",
    "\n",
    "# groups = {'acccuracy': ['train_acc', 'val_acc']}\n",
    "# plotlosses = PlotLosses(groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer(cfg['from_scratch'], train_id=\"scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
